{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobook Generator - Proof of Concept\n",
    "\n",
    "This notebook is intended to be a proof of concept for the end-to-end work of generating an audiobook file from an ebook. This includes converting the .epub book files into raw python trxt strings, splitting into items and sentences, then tokenizing and batching them to run through the Silero implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "torch.hub.download_url_to_file('https://raw.githubusercontent.com/snakers4/silero-models/master/models.yml',\n",
    "                               'latest_silero_models.yml',\n",
    "                               progress=False)\n",
    "models = OmegaConf.load('latest_silero_models.yml')\n",
    "\n",
    "seed = 1337\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg2554.epub = Crime and Punishment\n",
    "# pg174.epub = Portrait of Dorian Gray\n",
    "# pg1342.epub = Pride And Prejudice\n",
    "ebook_path = 'pg174.epub'\n",
    "sample_rate = 24000\n",
    "max_char_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/matthew/.cache/torch/hub/snakers4_silero-models_master\n"
     ]
    }
   ],
   "source": [
    "language = 'en'\n",
    "model_id = 'v3_en'\n",
    "speaker = 'en_0'\n",
    "\n",
    "model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
    "                                     model='silero_tts',\n",
    "                                     language=language,\n",
    "                                     speaker=model_id)\n",
    "model.to(device)  # gpu or cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ebook(ebook_path):\n",
    "    \n",
    "    import ebooklib\n",
    "    from ebooklib import epub\n",
    "    from bs4 import BeautifulSoup\n",
    "    from tqdm.notebook import tqdm\n",
    "    from nltk import tokenize, download\n",
    "    from textwrap import TextWrapper\n",
    "    \n",
    "    download('punkt')\n",
    "    wrapper = TextWrapper(max_char_len, fix_sentence_endings=True)\n",
    "    \n",
    "    book = epub.read_epub(ebook_path)\n",
    "\n",
    "    corpus = []\n",
    "    for item in tqdm(list(book.get_items())):\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            input_text = BeautifulSoup(item.get_content(), \"html.parser\").text\n",
    "            text_list = []\n",
    "            for paragraph in input_text.split('\\n'):\n",
    "                paragraph = paragraph.replace('â€”', '-')\n",
    "                sentences = tokenize.sent_tokenize(paragraph)\n",
    "                \n",
    "                # Truncate sentences to maximum character limit\n",
    "                sentence_list = []\n",
    "                for sentence in sentences:\n",
    "                    wrapped_sentences = wrapper.wrap(sentence)\n",
    "                    sentence_list.append(wrapped_sentences)\n",
    "                # Flatten list of list of sentences\n",
    "                trunc_sentences = [phrase for sublist in sentence_list for phrase in sublist]\n",
    "                \n",
    "                text_list.append(trunc_sentences)\n",
    "            text_list = [text for sentences in text_list for text in sentences]\n",
    "            corpus.append(text_list)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/matthew/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66d53fb5ea34d88bf3dbabc46640c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ebook = read_ebook(ebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c74a53d98048b7ac9a2327249e649d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe7606376ed64e59bc3646126ca36031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b194c869ff43fc9c817c206a26e480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f89922508742a59d23201735ba667b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/383 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba683518bd9d472aa7d768b523435813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ecd4ba0d96142b0a9f9afa9eac51893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f10945a9523423a93117edafc133769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe04efc7e114a80b18ae33efdb8be53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/440 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4872ec5996814ffa85a3c670a5cb59f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e240e2eddfe4314ad0490c478f4308b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/419 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4606b54fa1c44e60b35d851e32347749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4f43fac49a49a4a8f60d664393a245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/361 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82b1e06a3e44602afd17ae36cb02055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c24a73afcb744ca9caec69fd12df16f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71230cff029e4bebadb80f01ca09527f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57784e4adea14c2fa46bd44c7e875513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363741ae03f24ba5b847a52205214472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/405 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47b3c9a89da431f92ff832c7d81930c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29b5be3b38b43caa2f897ccc26268c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/275 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f189aa37a3c43cfa3b5f6afbd0a6caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6723a615fa64d43b21f2a008256b647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c276dfb8284e028bec0ae84b967456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/352 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474c6329acc04347b4398f50fff94a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fda20f04ce4256bfc6571da7af7a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 022 is empty.\n"
     ]
    }
   ],
   "source": [
    "for chapter in tqdm(ebook):\n",
    "    chapter_index = f'{ebook.index(chapter):03}'\n",
    "    audio_list = []\n",
    "    for sentence in tqdm(chapter):\n",
    "        audio = model.apply_tts(text=sentence,\n",
    "                            speaker=speaker,\n",
    "                            sample_rate=sample_rate)\n",
    "        if len(audio) > 0 and isinstance(audio, torch.Tensor):\n",
    "            audio_list.append(audio)\n",
    "        else:\n",
    "            print(f'Tensor for sentence is not valid: \\n {sentence}')\n",
    "\n",
    "    sample_path = \"outputs/silero/chapter\"+str(chapter_index)+\".wav\"\n",
    "    \n",
    "    if len(audio_list) > 0:\n",
    "        audio_file = torch.cat(audio_list).reshape(1,-1)\n",
    "        torchaudio.save(sample_path, audio_file, sample_rate)\n",
    "    else:\n",
    "        print(f'Chapter {chapter_index} is empty.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "##### CPU (i7-4790k)\n",
    "\n",
    "Running \"Pride and Prejudice\" through the Silero model took **34m42s** to convert. This book is a good representation of the average book length: the average audiobook length on Audible is between 10 & 12 hours, while Pride and Prejudice is 11h20m.\n",
    "\n",
    "This is approximately a 20:1 ratio of audio length to processing time.\n",
    "\n",
    "Pride and Prejudice: **34m42s** - 1h39m33s on i7-4650u\n",
    "\n",
    "Portrait of Dorian Gray: **18m18s** - 18m50s w/output\n",
    "\n",
    "Crime and Punishment: **Unknown** - error converting ebook at 7/50, 19/368\n",
    "\n",
    "##### GPU (P4000)\n",
    "\n",
    "Running the same book through the Silero model on GPU took **5m39s** to convert.\n",
    "\n",
    "This is approximately a 122:1 ratio of audio length to processing time.\n",
    "\n",
    "Pride and Prejudice: **5m39s**\n",
    "\n",
    "Portrait of Dorian Gray: **4m26s**\n",
    "\n",
    "Crime and Punishment: **Unknown** - error converting ebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
