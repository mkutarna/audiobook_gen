{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audiobook Generator - Proof of Concept\n",
    "\n",
    "This notebook is intended to be a proof of concept for the end-to-end work of generating an audiobook file from an ebook. This includes converting the .epub book files into raw python trxt strings, splitting into items and sentences, then tokenizing and batching them to run through the Nvidia implementation of Tacotron2.\n",
    "\n",
    "\n",
    "## Outline of steps\n",
    "\n",
    "1. Import .epub file\n",
    "2. Divide ebook into chapters\n",
    "3. Remove html tags\n",
    "4. Tokenize text for use in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import Audio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg2554.epub = Crime and Punishment\n",
    "# pg174.epub = Portrait of Dorian Gray\n",
    "# pg1342.epub = Pride And Prejudice\n",
    "ebook_path = 'pg2554.epub'\n",
    "rate = 22050\n",
    "batch_size = 100\n",
    "max_char_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nvidia-pyindex\n",
    "# !pip install pytorch-quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacotron2 = torch.hub.load(\n",
    "    'NVIDIA/DeepLearningExamples:torchhub', \n",
    "    'nvidia_tacotron2', \n",
    "    model_math='fp16',  \n",
    "    map_location=torch.device(device)\n",
    ")\n",
    "# tacotron2 = torch.hub.load_state_dict_from_url(\n",
    "#     'https://ngc.nvidia.com/catalog/models/nvidia:tacotron2pyt_fp32/files?version=3', \n",
    "#     map_location=torch.device(device)\n",
    "# )\n",
    "tacotron2 = tacotron2.to(device)\n",
    "# tacotron2 = tacotron2.eval()\n",
    "\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
    "\n",
    "waveglow = torch.hub.load(\n",
    "    'NVIDIA/DeepLearningExamples:torchhub', \n",
    "    'nvidia_waveglow', \n",
    "    model_math='fp16',  \n",
    "    map_location=torch.device(device)\n",
    ")\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to(device)\n",
    "waveglow = waveglow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ebook(ebook_path):\n",
    "    \n",
    "    import ebooklib\n",
    "    from ebooklib import epub\n",
    "    from bs4 import BeautifulSoup\n",
    "    from tqdm.notebook import tqdm\n",
    "    from nltk import tokenize, download\n",
    "    from textwrap import TextWrapper\n",
    "    \n",
    "    download('punkt')\n",
    "    wrapper = TextWrapper(max_char_len, fix_sentence_endings=True)\n",
    "    \n",
    "    book = epub.read_epub(ebook_path)\n",
    "\n",
    "    corpus = []\n",
    "    for item in tqdm(list(book.get_items())):\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            input_text = BeautifulSoup(item.get_content(), \"html.parser\").text\n",
    "            text_list = []\n",
    "            for paragraph in input_text.split('\\n'):\n",
    "                paragraph = paragraph.replace('â€”', '-')\n",
    "                sentences = tokenize.sent_tokenize(paragraph)\n",
    "                \n",
    "                # Truncate sentences to maximum character limit\n",
    "                sentence_list = []\n",
    "                for sentence in sentences:\n",
    "                    wrapped_sentences = wrapper.wrap(sentence)\n",
    "                    sentence_list.append(wrapped_sentences)\n",
    "                # Flatten list of list of sentences\n",
    "                trunc_sentences = [phrase for sublist in sentence_list for phrase in sublist]\n",
    "                \n",
    "                text_list.append(trunc_sentences)\n",
    "            text_list = [text for sentences in text_list for text in sentences]\n",
    "            corpus.append(text_list)\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebook = read_ebook(ebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebook[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(sentence) for chapter in ebook for sentence in chapter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ebook[6]\n",
    "text = [sentence[:max_char_len] for sentence in text]\n",
    "tokens, lengths = utils.prepare_input_sequence(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(tokens[i],lengths[i]) for i in range(len(tokens))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(data, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_list = []\n",
    "for X, length in tqdm(dataloader):\n",
    "    with torch.no_grad():\n",
    "        Y, _, _ = tacotron2.infer(X, length)\n",
    "        audio = waveglow.infer(Y)\n",
    "        audio_list.append(audio)\n",
    "#     audio_numpy = audio[0].data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50 * 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
